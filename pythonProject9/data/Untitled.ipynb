{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import tkinter.filedialog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "from pylatex import Document, table, MultiColumn, math\n",
    "\n",
    "\n",
    "from scipy import cluster\n",
    "from scipy import spatial\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", cluster.hierarchy.ClusterWarning)\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "scalar = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_string_list(data):\n",
    "    return ''.join('l' for x in range(len(data.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_string_list(data):\n",
    "    return ''.join('l' for x in range(len(data.columns)))\n",
    "def genenerate_longtabu(data):\n",
    "    print(len(generate_string_list(data)))\n",
    "    geometry_options = {\n",
    "        \"margin\": \"2.54cm\",\n",
    "        \"includeheadfoot\": True\n",
    "    }\n",
    "    doc = Document(page_numbers=True, geometry_options=geometry_options)\n",
    "\n",
    "    # Generate data table\n",
    "    with doc.create(table.LongTable('c|${generate_string_list(data)}')) as data_table:\n",
    "            data_table.add_hline()\n",
    "            data_table.add_row(data.columns)\n",
    "            data_table.add_hline()\n",
    "            data_table.end_table_header()\n",
    "            data_table.add_hline()\n",
    "            data_table.add_row((MultiColumn(len(data.columns), align='r',\n",
    "                                data='Continued on Next Page'),))\n",
    "            data_table.add_hline()\n",
    "            data_table.end_table_footer()\n",
    "            data_table.add_hline()\n",
    "            data_table.add_row((MultiColumn(3, align='r',\n",
    "                                data='Not Continued on Next Page'),))\n",
    "            data_table.add_hline()\n",
    "            data_table.end_table_last_footer()\n",
    "            row = [\"Content1\", \"9\", \"Longer String\"]\n",
    "            for i in range(data):\n",
    "                data_table.add_row(i)\n",
    "\n",
    "    doc.generate_pdf(\"longtable\", clean_tex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[153]:\n",
    "\n",
    "\n",
    "def get_xml_root():\n",
    "    etree = et.parse(tkinter.filedialog.askopenfilename())\n",
    "    return etree.getroot()\n",
    "\n",
    "\n",
    "# In[154]:\n",
    "\n",
    "\n",
    "def get_rules(xml_root):\n",
    "    rule_attr_list = [xml.attrib for xml in xml_root.iter('rule')]\n",
    "    rule_attr_dict = rule_attr_list.copy()\n",
    "    rule_attr_data_frame = pd.DataFrame(list(rule_attr_dict))\n",
    "    return rule_attr_data_frame\n",
    "\n",
    "\n",
    "# In[155]:\n",
    "\n",
    "\n",
    "def get_attributes(xml_root):\n",
    "    attribute_attr_list = [a.attrib for a in xml_root.find('attributes').iter('name')]\n",
    "    attribute_attr_dict = attribute_attr_list.copy()\n",
    "    attributes_attr_data_frame = pd.DataFrame(list(attribute_attr_dict))\n",
    "    attributes_attr_data_frame.drop('valueID', axis='columns', inplace=True)\n",
    "    attributes_attr_data_frame.dropna(subset=['attributeID'], inplace=True)\n",
    "    return attributes_attr_data_frame\n",
    "\n",
    "\n",
    "# In[156]:\n",
    "\n",
    "\n",
    "def init_rule_matrix(rule_data_frame, attribute_data_frame):\n",
    "    for x in attribute_data_frame.values:\n",
    "        rule_data_frame['attribute_' + x] = np.nan\n",
    "    return rule_data_frame\n",
    "\n",
    "\n",
    "# In[157]:\n",
    "\n",
    "\n",
    "def get_rule_by_id(xml_root, id_rule):\n",
    "    for rule in xml_root.iter('rule'):\n",
    "        if rule.attrib['ruleID'] == id_rule:\n",
    "            return rule\n",
    "\n",
    "\n",
    "# In[158]:\n",
    "\n",
    "\n",
    "def populate_matrix_with_conditions(xml_root, data_frame):\n",
    "    for i in range(len(list(data_frame.ruleID))):\n",
    "        for k in list(get_rule_by_id(xml_root, data_frame.ruleID[i]).find('conditions')):\n",
    "            data_frame.loc[\n",
    "                data_frame['ruleID'] == data_frame.ruleID[i], str(\n",
    "                    'attribute_' + list(k)[0].attrib['attributeID'])] = list(k)[2].text\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "# In[159]:\n",
    "\n",
    "\n",
    "def populate_matrix_with_conclusions(xml_root, data_frame):\n",
    "    for i in range(len(list(data_frame.ruleID))):\n",
    "        for k in list(get_rule_by_id(xml_root, data_frame.ruleID[i]).find('conclusion')):\n",
    "            data_frame.loc[\n",
    "                data_frame['ruleID'] == data_frame.ruleID[i], str(\n",
    "                    'attribute_' + list(k)[0].attrib['attributeID'])] = list(k)[2].text\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "# In[160]:\n",
    "\n",
    "\n",
    "def normilize_types_of_column_values(data_frame, column):\n",
    "    try:\n",
    "        data_frame[column] = pd.to_numeric(data_frame[column], downcast=\"float\")\n",
    "    except:\n",
    "        data_frame[column] = data_frame[column].astype(str)\n",
    "\n",
    "\n",
    "# In[161]:\n",
    "\n",
    "\n",
    "def get_simbolic_values(xml_root):\n",
    "    symbolic_value = []\n",
    "    t = [a for a in xml_root.find('attributes').iter('symbolic_value')]\n",
    "    for x in range(len(list(t))):\n",
    "        symbolic_value.append(list(t)[x].find('name').text)\n",
    "    return set(symbolic_value)\n",
    "\n",
    "\n",
    "# In[162]:\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "    return cluster.hierarchy.dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "# In[163]:\n",
    "\n",
    "\n",
    "def get_euclidean(data_for_linkage):\n",
    "    for linkage in ('ward', 'complete', 'average', 'single'):\n",
    "        condensed_euclidean_distance = spatial.distance.pdist(data_for_linkage, metric='euclidean')\n",
    "        distance_euclidean_matrix = spatial.distance.squareform(condensed_euclidean_distance)\n",
    "        linkage_distance = cluster.hierarchy.linkage(distance_euclidean_matrix, method=linkage)\n",
    "        dendrogram = cluster.hierarchy.dendrogram(linkage_distance, labels=data_for_linkage.index, leaf_font_size=12,\n",
    "                                                  leaf_rotation=45)\n",
    "        n_clusters = len(set(dendrogram['color_list'])) - 1\n",
    "        clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage=linkage)\n",
    "        clusterer.fit(data_for_linkage)\n",
    "        labels = clusterer.labels_\n",
    "        silhouette_avg = metrics.silhouette_score(distance_euclidean_matrix, labels, metric='precomputed')\n",
    "        plt.title(f'Hierarchical Clustering Dendrogram - {linkage} linkage , score: {silhouette_avg} ')\n",
    "        plt.suptitle('Euclidean')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def get_chebyshev(data_for_linkage):\n",
    "    for linkage in ('complete', 'average', 'single'):\n",
    "        condensed_chebyshev_distance = spatial.distance.pdist(data_for_linkage, metric='chebyshev')\n",
    "        distance_chebyshev_matrix = spatial.distance.squareform(condensed_chebyshev_distance)\n",
    "        linkage_distance = cluster.hierarchy.linkage(distance_chebyshev_matrix, method=linkage)\n",
    "        dendrogram = cluster.hierarchy.dendrogram(linkage_distance, labels=data_for_linkage.index, leaf_font_size=12,\n",
    "                                                  leaf_rotation=45)\n",
    "        n_clusters = len(set(dendrogram['color_list'])) - 1\n",
    "        clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage=linkage)\n",
    "        clusterer.fit(distance_chebyshev_matrix)\n",
    "        labels = clusterer.labels_\n",
    "        silhouette_avg = metrics.silhouette_score(distance_chebyshev_matrix, labels, metric='precomputed')\n",
    "        plt.title(f'Hierarchical Clustering Dendrogram - {linkage} linkage , score: {silhouette_avg} ')\n",
    "        plt.suptitle('Chebyshev')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root = get_xml_root()\n",
    "    rule_attrs = get_rules(root)\n",
    "    attribute_attrs = get_attributes(root)\n",
    "    init_data = init_rule_matrix(rule_attrs, attribute_attrs)\n",
    "    populate_matrix_with_conditions(root, init_data)\n",
    "    data = populate_matrix_with_conclusions(root, init_data)\n",
    "\n",
    "# In[164]:\n",
    "\n",
    "\n",
    "data.drop(data.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "indexed_data = data\n",
    "\n",
    "# In[169]:\n",
    "\n",
    "\n",
    "indexed_data = indexed_data.set_index('ruleID')\n",
    "\n",
    "for column in indexed_data.columns:\n",
    "    normilize_types_of_column_values(indexed_data, column)\n",
    "\n",
    "columns = list(indexed_data.columns)\n",
    "\n",
    "numerical_columns = []\n",
    "non_numerocal_columns = []\n",
    "for col in columns:\n",
    "    if col == 'ruleID':\n",
    "        continue\n",
    "    if np.issubdtype(indexed_data[col].dtype, np.number):\n",
    "        numerical_columns.append(col)\n",
    "    else:\n",
    "        non_numerocal_columns.append(col)\n",
    "\n",
    "# In[178]:\n",
    "\n",
    "\n",
    "numerical_data = indexed_data[numerical_columns]\n",
    "\n",
    "numerical_data = numerical_data.fillna(float(0))\n",
    "\n",
    "if len(numerical_columns) > 0:\n",
    "    scaled_data = scalar.fit_transform(numerical_data)\n",
    "    indexed_data[numerical_columns] = scaled_data\n",
    "\n",
    "symbolic_value = list(get_simbolic_values(root))\n",
    "symbolic_value.sort()\n",
    "\n",
    "for s in symbolic_value:\n",
    "    for categorical in non_numerocal_columns:\n",
    "        indexed_data.loc[indexed_data[categorical] == s, categorical] = symbolic_value.index(s)\n",
    "\n",
    "for categorical in non_numerocal_columns:\n",
    "    indexed_data.loc[indexed_data[categorical] == 'nan', categorical] = 8\n",
    "\n",
    "# print(indexed_data)\n",
    "\n",
    "# \"\"\"Euclidean distance with ward linkage\"\"\"\n",
    "# get_euclidean(indexed_data)\n",
    "# get_chebyshev(indexed_data)\n",
    "\n",
    "# condensed_chebyshev_distance = spatial.distance.pdist(indexed_data, metric='chebyshev')\n",
    "# distance_chebyshev_matrix = spatial.distance.squareform(condensed_chebyshev_distance)\n",
    "# linkage_1 = cluster.hierarchy.linkage(distance_chebyshev_matrix, method='single')\n",
    "# dendrogram_1 = cluster.hierarchy.dendrogram(linkage_1, labels=indexed_data.index, leaf_font_size=12, leaf_rotation=45)\n",
    "# n_clusters_1 = len(set(dendrogram['color_list'])) - 1\n",
    "# cluster_1 = AgglomerativeClustering(n_clusters=n_clusters_1, affinity='precomputed', linkage='single')\n",
    "# cluster_1.fit(indexed_data)\n",
    "# labels_1 = cluster_1.labels_\n",
    "# score_1 = metrics.silhouette_score(distance_chebyshev_matrix, labels_1, metric='precomputed')\n",
    "# print(score_1)\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_euclidean_distance = spatial.distance.pdist(indexed_data, metric='euclidean')\n",
    "distance_euclidean_matrix = spatial.distance.squareform(condensed_euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_matrix_frame = pd.DataFrame(distance_euclidean_matrix, index=indexed_data.index, columns=indexed_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1878', '1879', '1880', '1881', '1882', '1883', '1884', '1885', '1886',\n",
       "       '1887',\n",
       "       ...\n",
       "       '2284', '2285', '2286', '2287', '2288', '2289', '2290', '2291', '2292',\n",
       "       '2293'],\n",
       "      dtype='object', name='ruleID', length=416)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_matrix_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = math.Matrix(euclidean_matrix_frame, mtype='b', alignment='cr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.generate_tex(\"B\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
